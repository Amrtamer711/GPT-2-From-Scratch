{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "YHWpy8GQovL5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved model checkpoint\n",
        "path = \"/content/drive/MyDrive/GPT2/\"\n",
        "checkpoint_path = path + \"log/model_19072.pt\"\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "uUZSzu3Box4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model with GPT configuration\n",
        "config = GPTConfig(vocab_size=50304)\n",
        "model = GPT(config)\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device)['model'])\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Hs0ZlZHNo92X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "enc = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "-sKfS-1zo_Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_new_tokens = 100\n",
        "temperature = 1.0\n",
        "top_k = 50"
      ],
      "metadata": {
        "id": "eZ_pKHoYpBb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input prompt\n",
        "prompt = \"Hello, I'm a language model,\""
      ],
      "metadata": {
        "id": "Sm1KGwAUpDxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = enc.encode(prompt)\n",
        "x = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "# Generate new tokens\n",
        "outputs = model.generate(x, max_new_tokens=max_new_tokens, temperature=temperature, top_k=top_k)\n",
        "# Decode and print outputs\n",
        "outputs = [enc.decode(output.tolist()) for output in outputs]\n",
        "for text in outputs:\n",
        "    print(\"Generated Text:\\n\", text)"
      ],
      "metadata": {
        "id": "m0X-APZmpGeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}